


import requests
import pandas as pd
from bs4 import BeautifulSoup





# find url
url ='https://www.celltrionbeauty.com/main/best-items'






# request > response
response = requests.get(url)
response





# make BeautifulSoup Object
dom = BeautifulSoup(response.text, 'html.parser')
type(dom)


# find item list css selector
selector = '#productListBody > div' # 목록 데이터들 (40개) 영역을 CSS Selector로 가져옴 
elements = dom.select(selector)
len(elements)


# find item css selector
element = elements[0]
data = {
    'title' : element.select_one('.tit').text, # 제목 선택
    'price' : element.select_one('.pri').text, # 가격 선택
    'img'   : element.select_one('img').get('data-src'), #이미지 가져옴 , 이미지는 src= 속성 값을 가져와야함 : get('data-src')
    
    
    
}
#element 확인  
data


# parsing all elements
items = []
for element in elements:
    data = {
    'title' : element.select_one('.tit').text, # 제목 선택
    'price' : element.select_one('.pri').text, # 가격 선택
    'img'   : element.select_one('img').get('data-src'), #이미지 가져옴 , 이미지는 src= 속성 값을 가져와야함 : get('data-src')
    }
    items.append(data)
items[:3]




df = pd.DataFrame(items)
df.tail(2)





# 파일 시스템다룸 : 디렉 생성 
import os
# 이미지 전처리 
from PIL import Image as pil


# make directory
path = 'data'
os.makedirs(path, exist_ok = True)



os.listdir()


# download image
link = df.loc[0, 'img']
link


filename = 'test'
filelink = f'{path}/{filename}.jpg'

response = requests.get(link)

with open(filelink, 'wb') as file: # 파일을 바이너리 모드로 열어서('wb') HTTP 응답의 내용을 파일로 저장.
    file.write(response.content)


os.listdir(path)


# show image
pil.open(filelink)


# download images
# 크롤링 정책
# robots.txt파일 
# - 사람인, 잡코리아 수집해서 본인 서비스에 활용 했던 사례 
# - MIT 학생 논문(유료) 데이터 수집해서 다른 사람들과 공유함 
# - 서비스 피해: 지적재산권, 영업방해 가 될수 있음 
# - 가능한 API 서비스를 사용하는게 좋음 
