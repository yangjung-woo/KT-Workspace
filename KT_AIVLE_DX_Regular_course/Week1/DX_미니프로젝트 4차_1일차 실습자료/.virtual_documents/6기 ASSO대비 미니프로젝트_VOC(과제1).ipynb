








# 코드실행시 경고 메시지 무시
import warnings
warnings.filterwarnings(action='ignore')











# 여기에 답안코드를 작성하세요.
!pip install seaborn





# 여기에 답안코드를 작성하세요.
import numpy as np
import pandas as pd






# 여기에 답안코드를 작성하세요.
import matplotlib as plt
import seaborn as sns











# 여기에 답안코드를 작성하세요.
df = pd.read_csv('voc_data.csv')











# 여기에 답안코드를 작성하세요.
df.head(5)


# 여기에 답안코드를 작성하세요.
df.tail(5)





# 여기에 답안코드를 작성하세요.
df.info()






# 여기에 답안코드를 작성하세요.
df.index





# 여기에 답안코드를 작성하세요.
df.columns





# 여기에 답안코드를 작성하세요.
df.values





# 여기에 답안코드를 작성하세요.
df.describe() # 땡 틀렸음 >> Describe 






# 여기에 답안코드를 작성하세요.
df.isna().sum()
df.isnull().sum()






# 여기에 답안코드를 작성하세요.
df['voc_trt_perd_itg_cd'].values






# 여기에 답안코드를 작성하세요.

df['voc_trt_perd_itg_cd'].value_counts()











df


# 여기에 답안코드를 작성하세요.
drop_cols = ['voc_trt_perd_itg_cd']
df1 = df.drop(columns = drop_cols)





# 여기에 답안코드를 작성하세요.
drop_cols = ['voc_trt_reslt_itg_cd',
             'oos_cause_type_itg_cd',
             'engt_cperd_type_itg_cd',
             'engt_tgt_div_itg_cd',
             'fclt_oos_yn']
df1 = df1.drop(columns = drop_cols)





# 여기에 답안코드를 작성하세요. 
# 틀림 
# df1['cust_clas_itg_cd'].value_counts()
df1['cust_clas_itg_cd'].value_counts().get('_')





# 여기에 답안코드를 작성하세요.
# (오답) null = >  np.nan
df2 = df1.replace('_',np.nan)





# 여기에 답안코드를 작성하세요.
df2.isna().sum()






# 여기에 답안코드를 작성하세요.
df2.dtypes






# 여기에 답안코드를 작성하세요.
print(df2['cust_clas_itg_cd'].value_counts()) #.idxmax()[0] # 최빈값이 뭔지 확인 

df2['cust_clas_itg_cd'] = df2['cust_clas_itg_cd'].fillna('L')

df3 = df2.copy()


df3['cust_clas_itg_cd'].value_counts()





# 여기에 답안코드를 작성하세요.
# (땡)

# 문자열을 숫자형으로 변환 (errors='coerce'로 변환할 수 없는 값은 NaN으로 처리)
df3['age_itg_cd'] = pd.to_numeric(df3['age_itg_cd'], errors='coerce')

median_age = df3['age_itg_cd'].median(skipna=True) # nan 은 계산에서 제외 

df3['age_itg_cd'] = df3['age_itg_cd'].fillna(median_age).astype(int)

# 처리된 데이터프레임을 df4에 저장
df4 = df3.copy()





# 여기에 답안코드를 작성하세요.
most = df4['cont_sttus_itg_cd'].mode()[0]
# most 최빈값
df4['cont_sttus_itg_cd'] = df['cont_sttus_itg_cd'].fillna(most)

df5 = df4.copy()







# 여기에 답안코드를 작성하세요.
most2 = df5['cust_dtl_ctg_itg_cd'].mode()[0]

df5['cust_dtl_ctg_itg_cd'] = df5['cust_dtl_ctg_itg_cd'].fillna(most2)



df5





# 여기에 답안코드를 작성하세요.
#df5.dtypes
drop_cols = ['new_date','opn_nfl_chg_date','cont_fns_pam_date']
df5 = df5.drop(columns = drop_cols)
#df5.dtypes





# 여기에 답안코드를 작성하세요.
drop_cols = ['voc_mis_pbls_yn']
df5 = df5.drop(columns = drop_cols)









# 여기에 답안코드를 작성하세요.
cat_cols = df5.select_dtypes(include = 'object').columns
#cat_cols
from sklearn.preprocessing import LabelEncoder
labelEncoder = LabelEncoder()

df5['cust_clas_itg_cd'] = labelEncoder.fit_transform(df5['cust_clas_itg_cd'])

df5['cust_clas_itg_cd']





cat_cols


df5


# 여기에 답안코드를 작성하세요.
dummy_cols = ['cont_sttus_itg_cd', 'cust_dtl_ctg_itg_cd','trm_yn'] 
df6 = pd.get_dummies(df5, columns=dummy_cols, drop_first=True)


df6.info()


df6








# 여기에 답안코드를 작성하세요.
target = 'trm_yn_Y'  # 분류가  0 1 

y = df6[target]
x = df6.drop(columns = target)

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size= 0.2,stratify = y ,random_state = 42)












# 여기에 답안코드를 작성하세요.
from sklearn.preprocessing import StandardScaler 

Scaler = StandardScaler()

x_train = Scaler.fit_transform(x_train) # 
x_test = Scaler.transform(x_test)











# 여기에 답안코드를 작성하세요.
from sklearn.linear_model import LogisticRegression # 로지스틱 회귀 (분류모델)

model = LogisticRegression(C= 10 , max_iter = 2000)

model.fit(x_train, y_train)







# 여기에 답안코드를 작성하세요.
from sklearn.metrics import * 

y_pred = model.predict(x_test)

# heatmap 시각화 
sns.heatmap(confusion_matrix(y_test,y_pred),annot = True , cmap='Blues')
# 
print(classification_report(y_test,y_pred))






# 여기에 답안코드를 작성하세요.
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(max_depth = 10 ,random_state = 42)

model.fit(x_train,y_train)

y_pred = model.predict(x_test)

# heatmap 시각화 
sns.heatmap(confusion_matrix(y_test,y_pred), annot = True , cmap='Blues')
# 
print(classification_report(y_test,y_pred))






# 여기에 답안코드를 작성하세요.
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators = 100, random_state = 42)

model.fit(x_train,y_train)

y_pred = model.predict(x_test)

# heatmap 시각화 
sns.heatmap(confusion_matrix(y_test,y_pred),annot = True , cmap='Blues')
# 
print(classification_report(y_test,y_pred))





# 여기에 답안코드를 작성하세요.
from xgboost.sklearn import XGBClassifier

model = XGBClassifier(n_esrimators = 5)

model.fit(x_train,y_train)

y_pred = model.predict(x_test)

# heatmap 시각화 
sns.heatmap(confusion_matrix(y_test,y_pred),annot = True , cmap='Blues')
# 
print(classification_report(y_test,y_pred))






# 여기에 답안코드를 작성하세요.
from lightgbm  import LGBMClassifier

model = LGBMClassifier(n_estimators=3)
model.fit(x_train,y_train)

y_pred = model.predict(x_test)

# heatmap 시각화 
sns.heatmap(confusion_matrix(y_test,y_pred),annot = True , cmap='Blues')
# 
print(classification_report(y_test,y_pred))






# 이 데이터로 연습하세요.
x_data = np.array([1.6, 2.3, 3.5, 4.6]).reshape(-1,1)
y_data = np.array([3.3, 5.5, 7.2, 9.9])


# 여기에 답안코드를 작성하세요.
x_train2 , x_test2 , y_train2, y_test2 = train_test_split(x_data,y_data,test_size=0.3)

from sklearn.linear_model import LinearRegression
model= LinearRegression()
model.fit(x_train2,y_train2)

y_pred2 = model.predict(x_test2)

print("R2 Score:", r2_score(y_test2, y_pred2))
print("Mean Absolute Error:", mean_absolute_error(y_test2, y_pred2))












#!pip install keras


#!pip install tensorflow





# 여기에 답안코드를 작성하세요.
# 2) 라이브러리 불러오기 
from keras.models import Sequential
from keras.layers import Dense, Input
from keras.backend import clear_session
from keras.layers import Dropout
from keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

nfeatures = x_train.shape[1] #num of columns

clear_session()

model = Sequential([Input(shape = (nfeatures,)),
                    Dense(64,activation = 'relu'),
                    Dropout(0.2),
                    Dense(32,activation = 'relu'),
                    Dropout(0.2),
                    Dense(16,activation = 'relu'),
                    Dropout(0.2),
                    Dense(1, activation ='sigmoid')
                   ]
                
)
model.summary()
# model.compile(optimizer= Adam(learning_rate = 0.01), loss='binary_crossentropy' , ) # default 컴파일시 loss 만 추적하도록하는데 
model.compile(optimizer=Adam(learning_rate = 0.01), loss='binary_crossentropy', metrics=['accuracy']) # 컴파일시 loss 만 추적하도록하는데  정확도도 알고싶다면 metrics=['accuracy']를 추가하면 정확도도 알 수 있다

# 콜백 정의
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)

# 모델 학습
history = model.fit(
    x_train, y_train,
    batch_size=10,
    epochs=10,
    validation_data=(x_test, y_test),
    callbacks=[early_stopping, model_checkpoint]
)







# 여기에 답안코드를 작성하세요.

# (못풀었습니다)



# 참고
# Y 레이블 One-Hot-Encoding 되지 않았으면 loss='sparse_categorical_crossentropy' 사용
# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['acc'])
# history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[es,mc], validation_data=(X_test, y_test), verbose=1)


print(history.history.keys())  # 사용 가능한 메트릭 키 확인





# 여기에 답안코드를 작성하세요.
import matplotlib.pyplot as plt 

train_acc = history.history['accuracy']  
val_acc = history.history['val_accuracy']
# Epochs에 대한 x 값
epochs = range(1, len(train_acc) + 1)

plt.plot(epochs, train_acc, label='Train')
plt.plot(epochs, val_acc, label='Validation')
plt.title('Train and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()






# 여기에 답안코드를 작성하세요.
import matplotlib.pyplot as plt 
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Epochs에 대한 x 값
epochs = range(1, len(train_loss) + 1)

# 그래프 그리기
plt.plot(epochs, train_loss, label='Train')
plt.plot(epochs, val_loss, label='Validation')

# 그래프 제목 및 레이블 추가
plt.title('Train and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')

# 범례 표시
plt.legend()

# 그래프 출력
plt.show()





# 여기에 답안코드를 작성하세요.

# 모델 평가
y_pred = model.predict(x_test)

y_pred = np.where(y_pred >= .5, 1, 0)
print(y_pred)

print(classification_report(y_test, y_pred))



