








import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.simplefilter(action='ignore', category=Warning)

from sklearn.metrics import *
from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest





path = "https://raw.githubusercontent.com/DA4BAM/dataset/master/creditcard_simple.csv"
data = pd.read_csv(path)
data.head()


print(data['fraud'].value_counts())
print('='* 100)
print(data['fraud'].value_counts()/data.shape[0])








#from sklearn.model_selection import train_test_split
target = 'fraud'
x = data.drop(columns=target)
y = data.loc[:,target]


x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=6000, random_state=20)











# 최적의 contamination 찾기
result = []
conts = np.linspace(0.01, 0.5, 100)
for c in conts:
    model = IsolationForest(contamination = c, random_state = 20)
    model.fit(x_train)
    pred = model.predict(x_val)
    pred = np.where(pred == 1, 0, 1)
    result.append(f1_score(y_val, pred))


# 시각화 
print(round(max(result),3), round(conts[np.argmax(result)], 3) )
plt.plot(conts, result, marker = '.')
plt.grid()
plt.show()


# 최적의 contamination = 0.03    / score = 0.287








# 최적의 n_estimators 찾기
result = []
conts = np.arange(100, 201, 1)
for c in conts:
    model = IsolationForest(contamination =  0.03, n_estimators =c , random_state = 20)
    model.fit(x_train)
    pred = model.predict(x_val)
    pred = np.where(pred == 1, 0, 1)
    result.append(f1_score(y_val, pred))


# 시각화 
print(round(max(result),3), round(conts[np.argmax(result)], 3) )
plt.plot(conts, result, marker = '.')
plt.grid()
plt.show()


# 최적의 n_estimators 는 115 이다











from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import OneClassSVM












