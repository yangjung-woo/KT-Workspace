











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format='retina'


# 데이터 읽어오기
path = 'https://raw.githubusercontent.com/jangrae/csv/master/Attrition_simple2.csv'
data = pd.read_csv(path)





# 상위 몇 개 행 확인
data.head()





# target 값 확인 
data['Attrition'].value_counts(normalize= True)


# 기술통계 확인
data.describe()


# NaN 값 확인
data.isnull().sum()


# 상관관계 확인
data.corr(numeric_only=True)








# 제거 대상
drop_cols = ['EmployeeNumber']

# 변수 제거
data.drop(columns =drop_cols, inplace =True)

# 확인
data.head()





# target 확인
target = 'Attrition'
# 데이터 분리
x = data.drop(columns = target)
y = data.loc[:,target]






# 가변수화 대상
dummy_cols = ['JobSatisfaction','MaritalStatus','OverTime','Gender']

# 가변수화
x = pd.get_dummies(data= x , columns= dummy_cols, drop_first = True )

# 확인
x.head()





# 모듈 불러오기
from sklearn.model_selection import train_test_split

# 데이터 분리
x_train , x_test , y_train , y_test = train_test_split(x,y,random_state = 1 )





# 모듈 불러오기
from sklearn.preprocessing import MinMaxScaler

# 정규화
scaler = MinMaxScaler()
scaler.fit(x_train)

x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)





plt.boxplot(x_train,vert = False, labels = list(x))
plt.show()





# 1단계: 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix,classification_report


# 2단계: 선언하기
model = KNeighborsClassifier(n_neighbors = 5)


# 3단계: 학습하기
model.fit(x_train , y_train)


# 4단계: 예측하기
y_pred = model.predict(x_test)


# 5단계: 평가하기
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))


# 2. 테스트 데이터에 대해 최빈값으로 예측
y_pred2 = [y_train.mode()[0]] * len(y_test)

# 3. 최빈값 모델에 대한 성능 평가
print(classification_report(y_test, y_pred2))



