











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format = 'retina'


# https://raw.githubusercontent.com/jangrae/csv/master/Attrition_simple2.csv

path = 'https://raw.githubusercontent.com/jangrae/csv/master/Attrition_simple2.csv'
data = pd.read_csv(path)










#데이터 확인 
data.head()


#기술통계 확인
data.describe().T



#결측치 확인 
data.isna().sum()



#
data.info()



#










# EmployeeNumber 
data.drop(columns= 'EmployeeNumber',inplace = True)
data.head()





target = 'Attrition'
x = data.drop(columns = target)
y = data.loc[:,target]






dummy_cols = ['Gender','JobSatisfaction','MaritalStatus','OverTime']

x = pd.get_dummies(data=x , columns = dummy_cols , drop_first = True , dtype = int )
x.head()# light xbm을 위해서라도 문자열이 있어선 안된다 





from sklearn.model_selection import train_test_split

x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = 0.3)






from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaler.fit(x_train)

x_train_s = scaler.transform(x_train)
x_test_s = scaler.transform(x_test)







# xgboost 설치
# !pip install xgboost


# lightgbm 설치
# !pip install lightgbm





# 분류(이직 여부를 예측)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier

# 모델마다 최적의 파라미터를 찾아 학습
from sklearn.model_selection import GridSearchCV

# 모델 성능 평가
from sklearn.metrics import * 







# GridSearch 를 적용한 최적 모델을 확인 
param = {'n_neighbors': range(1, 21, 1)}
model_knn = GridSearchCV(KNeighborsClassifier(),param,cv = 5)
model_knn.fit(x_train_s, y_train) # (전체 학습)
# 예측 결과 확인
print('best params : ',model_knn.best_params_)
print('best_score : ',model_knn.best_score_) 

# # 2. 최적의 파라미터를 적용한 모델로 학습
# best_knn_model = model_knn.best_estimator_

# 3. x_test 데이터로 예측
y_pred = model_knn.predict(x_test_s)

# 4. 예측 성능 평가 (예: 정확도)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy}")





param = {'max_depth': range(1, 21, 1)}
model_dst = GridSearchCV(DecisionTreeClassifier(), param, cv = 5)
model_dst.fit(x_train, y_train) # (전체 학습)

# 예측 결과 확인
print('best params : ',model_dst.best_params_)
print('best_score : ',model_dst.best_score_) 

# # 2. 최적의 파라미터를 적용한 모델로 학습 (최적파라미터만 적용한 모델만 학습)
# best_dst_model = model_dst.best_estimator_

# 3. x_test 데이터로 예측
y_pred = model_dst.predict(x_test)

# 4. 예측 성능 평가 (예: 정확도)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy}")






param = {
    'max_depth': range(1, 21, 1)
}
model_rf = GridSearchCV(DecisionTreeClassifier(), param, cv = 5)
model_rf.fit(x_train, y_train)

# 예측 결과 확인
print('best params : ',model_rf.best_params_)
print('best_score : ',model_rf.best_score_) 

# # 2. 최적의 파라미터를 적용한 모델로 학습
# best_rf_model = model_rf.best_estimator_

# 3. x_test 데이터로 예측
y_pred = model_rf.predict(x_test)

# 4. 예측 성능 평가 (예: 정확도)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy}")






param = {'max_depth': range(1, 21, 1), 
         'n_estimators': range(50, 100, 10)}
model_lgbm = GridSearchCV(LGBMClassifier(verbose=-1), param , cv= 5)
model_lgbm.fit(x_train, y_train)

# 예측 결과 확인
print('best params : ',model_lgbm.best_params_)
print('best_score : ',model_lgbm.best_score_) 

# # 2. 최적의 파라미터를 적용한 모델로 학습
# best_lgbm_model = model_lgbm.best_estimator_

# 3. x_test 데이터로 예측
y_pred = model_lgbm.predict(x_test)

# 4. 예측 성능 평가 (예: 정확도)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy}")








# KNN 성능평가
y_pred = model_knn.predict(x_test_s)

# 평가하기
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))



# Decision Tree 성능평가
y_pred = model_dst.predict(x_test)

# 평가하기
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))


# Random Forest 모델 평가 
y_pred = model_rf.predict(x_test)

# 평가하기
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))


# light GBM 모델 평가
y_pred = model_lgbm.predict(x_test)

# 평가하기
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))



