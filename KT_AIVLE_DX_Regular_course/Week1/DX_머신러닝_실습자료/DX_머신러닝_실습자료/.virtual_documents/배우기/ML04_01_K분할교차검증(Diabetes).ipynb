











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format='retina'


# 데이터 읽어오기
path = 'https://raw.githubusercontent.com/Jangrae/csv/master/diabetes.csv'
data = pd.read_csv(path)





# 데이터 살펴보기
data.head()





# 기술통계 확인
data.describe()








# Target 확인
target = 'Outcome'

# 데이터 분리
x = data.drop(columns=target)
y = data.loc[:, target]





# 라이브러리 불러오기
from sklearn.model_selection import train_test_split

# 학습용, 평가용 데이터 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)





# 모듈 불러오기
from sklearn.preprocessing import MinMaxScaler

# 정규화
scaler = MinMaxScaler()
x_train_s = scaler.fit_transform(x_train)
x_test_s = scaler.transform(x_test)








# 불러오기
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

# 선언하기
model = DecisionTreeClassifier(max_depth=5,  random_state=1) # default = Accuracy

# 검증하기
cv_score = cross_val_score(model, x_train, y_train, cv=10)

# 확인
print(cv_score)
print('평균:', cv_score.mean()) # 정확도 
print('표준편차:', cv_score.std())

# 성능정보 수집 
result = {}
result['Decision Tree'] = cv_score.mean()





# 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

# 선언하기
model = KNeighborsClassifier()

# 검증하기
cv_score = cross_val_score(model,x_train,y_train,cv=10)# 모델, 학습용 데이터 x y , 분할개수 cv
cv_score = cross_val_score(model,x_train_s,y_train,cv=10) # 정규화를 수행한 학습데이터를 검증해 봤더니
# 정확도가 떨어짐 , scoring = 'recall' 재현률도 떨어짐 
# 확인
print(cv_score) # 정확도 10개 : 분할학습 한결과 10개 
print('평균:', cv_score.mean())
print('표준편차:', cv_score.std())

# 성능 정보 수집
result['KNN'] = cv_score.mean()





# 불러오기
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# 선언하기
model = LogisticRegression()

# 검증하기
cv_score = cross_val_score(model, x_train , y_train , cv = 10 )

# 확인
print(cv_score) # 정확도 10개 : 분할학습 한결과 10개 
print('평균:', cv_score.mean())
print('표준편차:', cv_score.std())

# 성능 정보 수집
result['Logistic Regression'] = cv_score.mean()


# result 성능 비교 
plt.barh(y= result.keys() ,width=result.values())





# 불러오기 
from sklearn.metrics import confusion_matrix ,classification_report

model = LogisticRegression()

model.fit(x_train,y_train)

y_pred = model.predict(x_test)

# 5단계 평가하기
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))




