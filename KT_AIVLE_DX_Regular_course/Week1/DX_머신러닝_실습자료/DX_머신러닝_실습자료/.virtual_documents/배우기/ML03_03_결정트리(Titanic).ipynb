











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format='retina'


# 데이터 읽어오기
path = 'https://raw.githubusercontent.com/jangrae/csv/master/titanic_train.csv'
data = pd.read_csv(path)





# 상위 몇 개 행 확인
data.head()


# 기술통계 확인
data.describe()


# Survived 확인
data['Survived'].value_counts()


# NaN 값 확인
data.isnull().sum()


# 상관관계 확인
data.corr(numeric_only=True)








# 제거 대상
drop_cols = ['PassengerId', 'Name', 'Ticket', 'Cabin']

# 변수 제거
data.drop(columns=drop_cols, inplace=True)

# 확인
data.head()





# Age 결측치를 중앙값으로 채우기
age_median = data['Age'].median()
data['Age'] = data['Age'].fillna(age_median)


# Embarked 최빈값으로 채우기
emb_freq = data['Embarked'].mode()[0]
data['Embarked'] = data['Embarked'].fillna(emb_freq)





# target 확인
target = 'Survived'

# 데이터 분리
x = data.drop(columns=target)
y = data.loc[:, target]





# 가변수화 대상
dumm_cols = ['Pclass', 'Sex', 'Embarked']

# 가변수화
x = pd.get_dummies(x, columns=dumm_cols, drop_first=True, dtype=int)

# 확인
x.head()





# 모듈 불러오기
from sklearn.model_selection import train_test_split

# 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1, stratify = y)





# 1단계: 불러오기
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report


# 2단계: 선언하기
model = DecisionTreeClassifier(max_depth = 5) # 시행마다 random_seed가 바뀐다 항상 같은결과 x 


# 3단계: 학습하기
model.fit(x_train, y_train)


# 4단계: 예측하기
y_pred = model.predict(x_test)


# 5단계 평가하기
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))








# 시각화 모듈 불러오기
from sklearn.tree import export_graphviz
from IPython.display import Image

# 이미지 파일 만들기
export_graphviz(model,                                 # 모델 이름
                out_file='tree.dot',                   # 파일 이름
                feature_names=list(x),                 # Feature 이름
                class_names=['die', 'survived'],       # Target Class 이름
                rounded=True,                          # 둥근 테두리
                max_depth = 3,                         # 출력할 최대 깊이
                precision=2,                           # 불순도 소숫점 자리수
                filled=True)                           # 박스 내부 채우기

# 파일 변환
!dot tree.dot -Tpng -otree.png -Gdpi=300

# 이미지 파일 표시
Image(filename='tree.png')





# 변수의 중요도를 보여줌
print()
print(model.feature_importances_)


# 변수 중요도
plt.figure(figsize=(5, 5))
plt.barh(y=list(x), width=model.feature_importances_)
plt.show()





# 데이터프레임 만들기
df = pd.DataFrame()
df['feature'] = list(x)
df['importance'] = model.feature_importances_
df.sort_values(by='importance', ascending=True, inplace=True)

# 시각화
plt.figure(figsize=(5, 5))
plt.barh(df['feature'], df['importance'])
plt.show()


# 가장 많은 불순도를 줄여준 변수: 1. Sex , 2. Age , 3. Fare
