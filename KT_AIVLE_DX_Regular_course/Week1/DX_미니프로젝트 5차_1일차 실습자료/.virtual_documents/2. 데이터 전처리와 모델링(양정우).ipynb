

















# 기본 경로
path = ''





# # 구글 드라이브 연결, 패스 지정
# import sys
# if 'google.colab' in sys.modules:
#     from google.colab import drive
#     drive.mount('/content/drive')
#     path = '/content/drive/MyDrive/project/'





# 라이브러리 불러오기
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import joblib

from sklearn.metrics import *
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from lightgbm import LGBMRegressor

import warnings
warnings.filterwarnings('ignore')
%config InlineBackend.figure_format = 'retina'





# 시각화 폰트 사이즈 설정
plt.rc('font', size=7)
plt.rc('xtick', labelsize=7)
plt.rc('ytick', labelsize=7)
plt.rc('axes', titlesize=8)
plt.rc('axes', labelsize=8)
plt.rc('legend', fontsize=8)
plt.rc('axes', linewidth=0.3)  # 축 테두리 굵기 설정





# 함수 만들기
def plot_model_result(y_train, y_val, y_pred, title=None):
    y_train = pd.Series(y_train)
    y_val = pd.Series(y_val)
    y_val.index = range(len(y_train), len(y_train) + len(y_val))
    y_pred = pd.Series(y_pred.reshape(-1,), index=y_val.index)

    # 시각화
    plt.figure(figsize=(12, 5))
    plt.subplot(2, 1, 1)
    plt.plot(y_train, label='y_train', color='tab:blue', linewidth=0.8)
    plt.plot(y_val, label='y_val', color='tab:green', linewidth=0.8)
    plt.plot(y_pred, label='y_pred', color='tab:orange', linewidth=0.8)
    plt.title(f'{title}', size=15, pad=20)
    plt.legend()

    plt.subplot(2, 1, 2)
    plt.plot(y_val, label = 'y_val', color='tab:green',  marker='o', markersize=2, linewidth=0.8)
    plt.plot(y_pred, label = 'y_pred', color='tab:orange',  marker='o', markersize=2, linewidth=0.8)
    plt.legend()
    plt.tight_layout()
    plt.show()








# 데이터 불러오기
sales = pd.read_csv(path + 'sales_train.csv')
orders = pd.read_csv(path + 'orders_train.csv')
oil_price = pd.read_csv(path + 'oil_price_train.csv')
stores = pd.read_csv(path + 'stores.csv')
products = pd.read_csv(path + 'products.csv')


# datetime 형으로 변환
sales['date'] = pd.to_datetime(sales['date'] )
oil_price['date'] = pd.to_datetime(oil_price['date'] )
orders['date'] = pd.to_datetime(orders['date'] )





sales.describe() # 2014-01-02 00:00:00 ~ 2017-02-28 00:00:00


orders.describe() # 2014-01-02 00:00:00 ~ 2017-02-28 00:00:00


oil_price.describe() # 2014-01-02 00:00:00 ~ 2017-02-28 00:00:00


stores.value_counts() # date 시계열 정보는 없음 대신 매장 정보를 알 수 있음
# target 매장 id: 44        도시:Saint Paul     주: Minnesota       store_ type:1  


products.value_counts() # 상품 정보 ,   
# product_id  product_code  subcategory      category         leadtime  price
# 3           DB001         Beverage         Drink            2         8
# 7           HC001         Cleaning         Household Goods  2         15
# 12          GA001         Milk             Food             2         6








# 함수 만들기
def make_dataset_prototype(store_id, product_id): 
    '''
    products , sales , orders 데이터셋에서 store_id에 해당하는 데이터들을 가져옴 
    col = [date	qty	 count	weekday	 month	wti_price	target]
    
    '''
    # 데이터 준비
    leadtime = products.loc[products['product_id']==product_id, 'leadtime'].values[0]
    temp1 = sales.loc[(sales['store_id']==store_id) & (sales['product_id']==product_id), ['date', 'qty']]
    temp2 = orders.loc[orders['store_id']==store_id, ['date', 'count']]
    temp3 = pd.merge(temp1, temp2, on='date', how='left')

    # 날짜 요소 추출
    temp3['weekday'] = temp3['date'].dt.day_name()
    temp3['month'] = temp3['date'].dt.month

    # Oil Price
    temp3 = pd.merge(temp3, oil_price, on='date', how='left')
    temp3['wti_price'] = temp3['wti_price'].rolling(14, min_periods=1).mean()# 지난 14일간 유가 평균 

    # Target 추가   = 2일 후 판매량을 예측 
    temp3['target'] = temp3['qty'].shift(-leadtime)

    # 결측치 처리
    temp3.interpolate(method='linear', inplace=True)
    temp3.bfill(inplace=True)

    # 결과 반환
    return temp3





# 상품별 데이터 셋
data03 = make_dataset_prototype(44, 3)
data07 = make_dataset_prototype(44, 7)
data12 = make_dataset_prototype(44, 12)


# 확인
display(data03.head())
display(data07.head())
display(data12.head())








# 함수 만들기
def preproc(data):
    # x, y 분리
    y= data['target']
    x= data.drop(columns= ['date','target'])
    # 가변수화 : 가변수화 할 컬럼 =  weekday , month 
    dummy_cols = ['weekday','month']
    months = [1,2,3,4,5,6,7,8,9,10,11,12]
    x['month'] = pd.Categorical(x['month'],categories= months)
    x = pd.get_dummies(data=x, columns = dummy_cols , drop_first=True)

    # 학습용, 검증용 분리
    x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=120, shuffle =False)

    # 결과 반환
    return x_train, x_val, y_train, y_val





data03


x_train, x_val, y_train, y_val = preproc(data03)




x_train


y_train





x_train, x_val, y_train, y_val = preproc(data07)





x_train, x_val, y_train, y_val = preproc(data12)











!pip install yfinance


import yfinance as yf
# 미국 10년 국채 금리 데이터를 가져오는 예시 (US10Y)
finance = yf.download('^TNX', start='2014-01-01', end='2017-02-28')  # 미국 10년 국채 금리

finance = finance.reset_index()
# 미국 10년 국채 금리는 시장에서 중요한 경제적 신뢰도를 반영합니다. 
# 높은 금리는 일반적으로 경제 성장과 인플레이션 우려와 관련이 있고,  >> 높으면  경제성장
# 낮은 금리는 경기 침체나 경제 불확실성과 관련이 있습니다           >> 낮으면 경제 침체
# 이중에서 당일 종가 데이터만 가져오기에 Close 만 가져오자  (Adj Close 수정된 종가는 Close와 같음 )
# # 'Date' 컬럼에서 날짜만 추출하여 '년-월-일' 형식으로 변경
finance['Date'] = pd.to_datetime(finance['Date']).dt.strftime('%Y-%m-%d')

# # 'Close'와 'Date' 컬럼만 선택
bond_data = finance[['Date', 'Close']]
# ticket, price 인덱스 제거 
bond_data = bond_data.reset_index()

# 날짜를 인덱스로 설정하고 날짜 범위에 맞는 모든 날짜 생성
bond_data['Date'] = pd.to_datetime(bond_data['Date'])
date_range = pd.date_range(start='2014-01-02', end='2017-02-28')

# 모든 날짜에 대해 종가를 채우기 전에, 데이터를 날짜별로 정렬
data_sorted = bond_data.set_index('Date').reindex(date_range)

# 전날 종가로 결측치를 채움
data_sorted['Close'] = data_sorted['Close'].fillna(method='ffill')

# 인덱스를 컬럼으로 다시 리셋
data_final = data_sorted.reset_index()
# 불필요한 컬럼 제거: 'Price', 'level_0', 'index', 'Ticker' 등을 제거
data_final_cleaned = data_final.drop(columns=['index'])

# 컬럼명 변경
data_final_cleaned.rename(columns={'level_0': 'date'}, inplace=True)
data_final_cleaned.columns = ['date', 'FOMC']
# 결과 확인
interest_rate = data_final_cleaned.copy()
interest_rate


# # 함수 만들기(수정 필요)(양정우 버전)
# def make_dataset(store_id, product_id):
#     # 데이터 준비
#     leadtime = products.loc[products['product_id']==product_id, 'leadtime'].values[0]
#     temp1 = sales.loc[(sales['store_id']==store_id) & (sales['product_id']==product_id), ['date', 'qty']]
#     temp2 = orders.loc[orders['store_id']==store_id, ['date', 'count']]
#     temp3 = pd.merge(temp1, temp2, on='date', how='left')
    
#     # 날짜 요소 추출
#     temp3['weekday'] = temp3['date'].dt.day_name()
#     temp3['month'] = temp3['date'].dt.month
    
#     # Oil Price
#     temp3 = pd.merge(temp3, oil_price, on='date', how='left')
#     temp3['wti_price'] = temp3['wti_price'].rolling(14, min_periods=1).mean()

#     #category_qty: 동일 카테고리 판매량 합계
#     category_name =  products.loc[products['product_id'] ==product_id]['category'].values[0]
#     category_chain = products.loc[products['category']==category_name]['product_id'].values
#     related_sales = sales.loc[(sales['store_id'] == store_id) & (sales['product_id'].isin(category_chain))]
#     related_sales = related_sales.groupby('date')['qty'].sum().reset_index()
#     related_sales = related_sales.rename(columns={'qty':'category_qty'})
#     temp3 = pd.merge(temp3,related_sales,on='date',how='left')  

#     #city_custcount: 동일 지역 방문객 수  stores에  store_id ,  city ,state가 있음, orders에 store_id 와 count 가 있음                            
#     #city = Saint Paul 밖에 없음  [city를 기준]
#     city_name = stores.loc[stores['store_id']==store_id]['city'].values[0]
#     city_chain = stores.loc[stores['city']==city_name]['store_id'].values
#     related_count = orders.loc[(orders['store_id'].isin(city_chain))]
#     related_count = related_count.groupby('date')['count'].sum().reset_index()
#     related_count = related_count.rename(columns={'count':'city_custcount'})
#     temp3 = pd.merge(temp3,related_count,on='date',how='left')

#     #qty_lag_1: 1일 전 판매량    sales 안에 qty 열 
#     temp3['qty_lag_1'] = temp3['qty'].shift(1)
    
#     #qty_lag_2: 2일 전 판매량    sales 안에 qty 열 
#     temp3['qty_lag_2'] = temp3['qty'].shift(2)
    
#     #qty_lag_5: 5일 전 판매량    sales 안에 qty 열 
#     temp3['qty_lag_5'] = temp3['qty'].shift(5)
    
#     #qty_lag_7: 7일 전 판매량    sales 안에 qty 열 
#     temp3['qty_lag_7'] = temp3['qty'].shift(7)
    
#     #qty_lag_7_mean: 최근 7일간 판매량 평균
#     temp3['qty_lag_7_mean'] = temp3['qty'].rolling(7, min_periods=1).mean()

#     #qty_lag_14_mean: 최근 14일간 판매량 평균
#     temp3['qty_lag_14_mean'] = temp3['qty'].rolling(14, min_periods=1).mean()
    
#     # (추가) 특정요일 추가  >> 토, 일에 높은 판매량이 예상되므로 2일전  목,금 인지 여부를 넣으면 잘 파악할거같음 
#     temp3['predict_peek'] = temp3['weekday'].isin(['Thursday', 'Friday'])
#     # (추가) 미국 당일 금리를 추가 
#     temp3 = pd.merge(temp3, interest_rate, on='date', how='left')
#     # Target 추가
#     temp3['target'] = temp3['qty'].shift(-leadtime)

    
#     # 결측치 처리
#     temp3.interpolate(method='linear', inplace=True)
#     temp3.fillna(method='bfill', inplace=True)

#     # 결과 반환
#     return temp3


# 함수 만들기(수정 필요) (김명제님 )
def make_dataset(store_id, product_id):
    # 데이터 준비
    leadtime = products.loc[products['product_id']==product_id, 'leadtime'].values[0]
    temp1 = sales.loc[(sales['store_id']==store_id) & (sales['product_id']==product_id), ['date', 'qty']]
    temp2 = orders.loc[orders['store_id']==store_id, ['date', 'count']]
    temp3 = pd.merge(temp1, temp2, on='date', how='left')
 
    # 날짜 요소 추출
    temp3['weekday'] = temp3['date'].dt.day_name()
    temp3['month'] = temp3['date'].dt.month
 
    # Oil Price
    temp3 = pd.merge(temp3, oil_price, on='date', how='left')
    temp3['wti_price'] = temp3['wti_price'].rolling(14, min_periods=1).mean()
 
    # 추가(날짜)
    temp3['day'] = temp3['date'].dt.day
    temp3['is_weekend'] = temp3['weekday'].isin(['Saturday', 'Sunday']).astype(int)
    temp3['quarter'] = temp3['date'].dt.quarter
    temp3['is_quarter_start'] = temp3['date'].dt.is_quarter_start.astype(int)
    temp3['is_quarter_end'] = temp3['date'].dt.is_quarter_end.astype(int)
    temp3['week'] = temp3['date'].dt.isocalendar().week
    temp3['is_month_start'] = temp3['date'].dt.is_month_start.astype(int)
    temp3['is_month_end'] = temp3['date'].dt.is_month_end.astype(int)
    temp3['is_year_start'] = temp3['date'].dt.is_year_start.astype(int)
    temp3['is_year_end'] = temp3['date'].dt.is_year_end.astype(int)
 
    # 추가(qty lag)
    temp3['qty_lag_1'] = temp3['qty'].shift(1)
    temp3['qty_lag_2'] = temp3['qty'].shift(2)
    temp3['qty_lag_3'] = temp3['qty'].shift(3)
    temp3['qty_lag_4'] = temp3['qty'].shift(4)
    temp3['qty_lag_5'] = temp3['qty'].shift(5)
    temp3['qty_lag_6'] = temp3['qty'].shift(6)
    temp3['qty_lag_7'] = temp3['qty'].shift(7)
    temp3['qty_lag_14'] = temp3['qty'].shift(14)
 
    # 추가(방문수)
    temp3['count_mean3'] = temp3['count'].rolling(window=3, min_periods=1).mean()
    temp3['count_mean7'] = temp3['count'].rolling(window=7, min_periods=1).mean()
    temp3['count_mean14'] = temp3['count'].rolling(window=14, min_periods=1).mean()
    temp3['qty_per_customer'] = temp3['qty'] / temp3['count']
    temp3['count_std7'] = temp3['count'].rolling(window=7, min_periods=1).std()
 
    # 판매량
    temp3['qty_max7'] = temp3['qty'].rolling(window=7, min_periods=1).max()
    temp3['qty_min7'] = temp3['qty'].rolling(window=7, min_periods=1).min()
    temp3['qty_mean7'] = temp3['qty'].rolling(window=7, min_periods=1).mean()
    # 카테고리
    category = products.loc[products['product_id']==product_id, 'category'].values[0]
    category_products = products.loc[products['category']==category, 'product_id'].values
    category_sales = sales.loc[(sales['store_id']==store_id) &
                             (sales['product_id'].isin(category_products)),
                             ['date', 'qty']].groupby('date')['qty'].sum().reset_index()
    category_sales.columns = ['date', 'qty_category']
    temp3 = pd.merge(temp3, category_sales, on='date', how='left')
    temp3['category_mean7'] = temp3['qty_category'].rolling(window=7, min_periods=1).mean()
    temp3['category_min7'] = temp3['qty_category'].rolling(window=7, min_periods=1).min()

    # 주간 누적 판매량 (추가)
    temp3['weekly_qty_sum'] = temp3['qty'].rolling(7, min_periods=1).sum()
    # 도시
    city = stores.loc[stores['store_id']==store_id, 'city'].values[0]
    city_stores = stores.loc[stores['city']==city, 'store_id'].values
    city_customers = orders.loc[orders['store_id'].isin(city_stores),
                              ['date', 'count']].groupby('date')['count'].sum().reset_index()
    temp3 = pd.merge(temp3, city_customers, on='date', how='left', suffixes=('', '_city'))
    temp3['city_count_ma7'] = temp3['count_city'].rolling(window=7, min_periods=1).mean()
    temp3['city_count_std7'] = temp3['count_city'].rolling(window=7, min_periods=1).std()


    # (추가) 미국 당일 금리를 추가 
    temp3 = pd.merge(temp3, interest_rate, on='date', how='left') 
    # (추가) (요일별 평균)
    temp3['weekday_avg_qty'] = temp3.groupby('weekday')['qty'].transform('mean')
    #(추가) 월초 , 월밀 = 월급날 > 소비증가 > 매출증가 
    temp3['is_first_week'] = (temp3['date'].dt.day <= 7).astype(int)
    temp3['is_last_week'] = (temp3['date'].dt.day >= 25).astype(int)

    
    # Target 추가
    temp3['target'] = temp3['qty'].shift(-leadtime)
 
    # 결측치 처리
    temp3.interpolate(method='linear', inplace=True)
    temp3.fillna(method='bfill', inplace=True)
 
    # 결과 반환
    return temp3





data03 = make_dataset(44,3)
data07 = make_dataset(44,7)
data12 = make_dataset(44,12)


data03








from sklearn.preprocessing import StandardScaler


from sklearn.linear_model import LinearRegression

x_train, x_val, y_train, y_val = preproc(data03)
x_train = x_train.astype(float)
x_val = x_val.astype(float)


# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)


# Linear 선형회귀 모델은 모든 데이터 형식이 float으로 통일해야 합니다 > 가변수화 한 데이터의 타입 변경
model03_lin = LinearRegression()
model03_lin.fit(x_train,y_train)

y_pred = model03_lin.predict(x_val)
plot_model_result(y_train,y_val,y_pred)
print(model03_lin.score(x_val,y_val))

print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))





x_train, x_val, y_train, y_val = preproc(data07)
x_train = x_train.astype(float)
x_val = x_val.astype(float)


# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)


model07_lin = LinearRegression()
model07_lin.fit(x_train,y_train)
y_pred = model07_lin.predict(x_val)

# 평가
plot_model_result(y_train,y_val,y_pred)
print(model07_lin.score(x_val,y_val))
print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))





x_train, x_val, y_train, y_val = preproc(data12)
x_train = x_train.astype(float)
x_val = x_val.astype(float)


# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)


model12_lin = LinearRegression()
model12_lin.fit(x_train,y_train)
y_pred = model12_lin.predict(x_val)

# 평가
plot_model_result(y_train,y_val,y_pred)
print(model12_lin.score(x_val,y_val))
print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))












x_train, x_val, y_train, y_val = preproc(data03)
# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)

model03_rdf = RandomForestRegressor()
model03_rdf.fit(x_train,y_train)
model03_rdf.score(x_val,y_val)
y_pred = model03_rdf.predict(x_val)
# 평가
plot_model_result(y_train,y_val,y_pred)
print(model03_rdf.score(x_val,y_val))

print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))





x_train, x_val, y_train, y_val = preproc(data07)
# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)

model07_rdf = RandomForestRegressor()
model07_rdf.fit(x_train,y_train)
y_pred = model07_rdf.predict(x_val)
# 평가
plot_model_result(y_train,y_val,y_pred)
print(model07_rdf.score(x_val,y_val))

print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))





x_train, x_val, y_train, y_val = preproc(data12)

# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)

model12_rdf = RandomForestRegressor()
model12_rdf.fit(x_train,y_train)
y_pred = model12_rdf.predict(x_val)
# 평가
plot_model_result(y_train,y_val,y_pred)
print(model12_rdf.score(x_val,y_val))

print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))










x_train, x_val, y_train, y_val = preproc(data03)
# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)

model03_lgb = LGBMRegressor()
model03_lgb.fit(x_train,y_train)
y_pred = model03_lgb.predict(x_val)

# 평가
plot_model_result(y_train,y_val,y_pred , title='LGBM model with 3')
print(model03_lgb.score(x_val,y_val))


print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))





x_train, x_val, y_train, y_val = preproc(data07)
# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)

model07_lgb = LGBMRegressor()
model07_lgb.fit(x_train,y_train)
y_pred = model07_lgb.predict(x_val)
# 평가
plot_model_result(y_train,y_val,y_pred)
print(model07_lgb.score(x_val,y_val))

print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))


x_train





x_train, x_val, y_train, y_val = preproc(data12)
# 스케일링
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_val = scaler.transform(x_val)

model12_lgb = LGBMRegressor()
model12_lgb.fit(x_train,y_train)
y_pred = model12_lgb.predict(x_val)

# 평가
plot_model_result(y_train,y_val,y_pred)
print(model12_lgb.score(x_val,y_val))

print("RMSE:", np.sqrt(mean_squared_error(y_val, y_pred)))
print("MAE:", mean_absolute_error(y_val, y_pred))
print("MAPE:", f"{mean_absolute_percentage_error(y_val, y_pred) * 100:.2f}%")
print("R2-Score:", r2_score(y_val, y_pred))





# 파일 저장
joblib.dump(data03, path + 'data03.pkl')
joblib.dump(data07, path + 'data07.pkl')
joblib.dump(data12, path + 'data12.pkl')


df = joblib.load('data03.pkl')
# 데이터프레임 출력 (옵션)
print(df.head())


df = joblib.load('data07.pkl')
# 데이터프레임 출력 (옵션)
print(df.head())


df = joblib.load('data12.pkl')
# 데이터프레임 출력 (옵션)
print(df.head())



