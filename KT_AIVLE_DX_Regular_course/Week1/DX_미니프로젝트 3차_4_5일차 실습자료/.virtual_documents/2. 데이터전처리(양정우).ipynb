




















#[문제 1] 필요 라이브러리 로딩
# numpy, pandas, matplotlib, seaborn, os 를 임포트 하기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os



# 한글 세팅

plt.rc("font", family = "Malgun Gothic")
sns.set(font="Malgun Gothic",
rc={"axes.unicode_minus":False}, style='white')


# [문제 2] 데이터 불러오기
# data 변수에 'customers_seg.csv' 파일을 불러오기
data = pd.read_csv('customers_seg.csv')




# [문제 3] 데이터 상위 5개 조회
data.head()






# [문제 4] 데이터 셋의 모든 컬럼명(변수명)을 확인해보자.(columns로 확인)

data.columns


# [문제 5] mission 1에서 선정한 11개의 변수만 가지고 있는 데이터 프레임 생성하기

# 1. data를 data_choice 변수에 copy 해놓기
data_choice = data.copy()


# 2. col 에 선정한 11개 변수를 리스트로 할당해보자.
#[참고] 11개 변수: 'AGE', '고용상태', 'Willingness to pay/Stay', '상품타입',
# '교육수준', '소득', '월 납입액','타 상품 보유 현황', '총지불금액', '거주지사이즈','자동차'
columns = ['AGE','고용상태','교육수준','상품타입','거주지사이즈','자동차','Willingness to pay/Stay','소득','월 납입액','타 상품 보유 현황','총지불금액']
# 3.data_choice 변수에 col 할당 후 data_choice 데이터를 확인해보자.

data_choice = data_choice[columns]
data_choice.head()









# [문제 6] 범주형 변수가 무엇이 있는지 확인해보자(info 활용)
data_choice.info()


















# [문제 7] '고용상태' 범주 종류 확인(.unique() 혹은 .value_counts())
data_choice['고용상태'].value_counts()


# [같이 하기]'고용상태' 범주를 인코딩 해보기
# np.where 을 이용해서 조건에 따른 값으로 변환하기
# 고용상태가 '고용' 이면 1, 아니면 0

data_choice['고용상태'] = np.where(data_choice['고용상태'] == '고용', 1, 0)


#[같이 하기] '고용상태'가 변환된 것을 확인해보기

data_choice.head()








# [문제 8] '상품타입' 범주와 비율 확인
data_choice['상품타입'].value_counts()


# [문제 9]'상품타입'범주를 인코딩 해보기
# '상품타입'이 '고급' 1, 아니면 0

data_choice['상품타입'] = np.where(data_choice['상품타입'] == '고급', 1, 0)


#[문제 10] '상품타입'이 변환된 것을 확인해보기
data_choice.head()






#[문제 11] '교육수준' 범주와 비율 확인
target = '교육수준' 
data_choice[target].value_counts()



#[문제 12]'교육수준' 범주를 인코딩 해보기
# '교육수준'이 '석사' 혹은 '박사'이면 1, 아니면 0

data_choice[target] = np.where( data_choice[target].isin(['석사','박사']), 1, 0)


#[문제 13] '교육수준'이 변환된 것을 확인해보기

data_choice[target].value_counts()





#[문제 14] '타 상품 보유 현황' 범주와 비율 확인

target = '타 상품 보유 현황'
data_choice[target].value_counts()


# [문제 15] 문자열 제거 하기
# '타 상품 보유 현황'은 숫자형 이지만, 4이상의 '이상'이라는 문자열을 제거해서 정리가 필요
# np.where를 이용해서 '이상'을 제거해 봅시다.
data_choice[target] = np.where(data_choice[target].str.contains('이상'),  # '이상' 이라는 문자를 포함하면
                               data_choice[target].str.replace('이상', ''),  # 제거 
                               data_choice[target])
data_choice[target] = data_choice[target].astype(int)



#[문제 16]'타 상품 보유 현황'이 변환된 것을 확인해보기
data_choice[target].value_counts()






#[문제 17] '거주지사이즈' 범주와 비율 확인

target = '거주지사이즈'
data_choice[target].value_counts()


#[문제 18]'거주지사이즈' 범주를 인코딩 해보기
# '대'를 1, 나머지를 0

data_choice[target] = np.where( data_choice[target] == '대', 1, 0)


#[문제 19]'거주지사이즈'가 변환된 것을 확인해보기
data_choice[target].value_counts()






#[문제 20] '자동차' 범주와 비율 확인

target = '자동차'
data_choice[target].value_counts()


#[문제 21]'자동차' 범주를 인코딩 해보기
# 고급차,스포츠카를 1로. 나머지는 0

data_choice[target] = np.where( data_choice[target].isin(['고급차','스포츠카']), 1, 0)


#[문제 22] '자동차'가 변환된 것을 확인해보기
data_choice[target].value_counts()












#[문제 40] standard-scaling을 해보자.

# 1. standard-scaler import!(sklearn의 processing 활용)
from sklearn.preprocessing import StandardScaler


# 2. scaler라는 변수에 StandardScaler 넣어주기
scaler = StandardScaler()
# 

# 스케일링이 필요한 변수 
# (주의) 범주의미를 갖지만 0 1 2 3 4   순서의 의미를 갖는 변수들은 스케일링을 해줘야 한다 
#scale_cols = ['Willingness to pay/Stay','소득','월 납입액' ,'총지불금액']
columns = ['AGE','고용상태','교육수준','상품타입','거주지사이즈','자동차','Willingness to pay/Stay','소득','월 납입액','타 상품 보유 현황','총지불금액']

# 3. 'data_choice'을  fit_transform 하여 'data_sc'로 저장
# 단, 데이터프레임을 스케일링하면, 결과가 넘파이 어레이로 나온다.
# 그래서 데이터프레임으로 다시 변환할 필요가 있다.(이때 칼럼 이름 필요)

# scale_cols에 해당하는 변수들만 스케일링
scaled_data = scaler.fit_transform(data_choice)

# 스케일링된 데이터프레임을 scale_cols 컬럼명으로 생성
scaled_df = pd.DataFrame(scaled_data, columns=columns)

# 스케일링된 컬럼들을 data_choice의 나머지 컬럼들과 병합
data_sc = data_choice.copy()  # 원본 데이터프레임 복사
data_sc = scaled_df  # 스케일링된 컬럼만 교체



# [문제 41] 스케일링이 잘 되었는지 'data_sc' 데이터를 확인해보자

data_sc


#[문제 42] 데이터 내보내기
# 2일차에 모델링에 활용하기 위해 내보내기를 해보자.
# data_sc 를 data_sc.csv 파일로 저장(to_csv 활용)
# index=False 파라미터를 설정해 줘야지 unnamed:0번 추가 인덱스가 안생기기에 꼭! 넣어서 저장!
data_sc.to_csv('data_sc.csv', index=False)



#[문제 43] 데이터가 잘 들어갔는지 read_csv 활용해서 'data_sc.csv' 확인
df = pd.read_csv('data_sc.csv')
df












